{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESMfold embedding\n",
    "\n",
    "> A collection of plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastbook import *\n",
    "from fairscale.nn.data_parallel import FullyShardedDataParallel as FSDP\n",
    "from fairscale.nn.wrap import enable_wrap, wrap\n",
    "import esm\n",
    "from tqdm.notebook import tqdm; tqdm.pandas()\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def esm_embeddings(df: pd.DataFrame, colname: str, model_name: str = \"esm2_t33_650M_UR50D\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract ESM embeddings from a DataFrame using the specified ESM model and feature extraction function.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: pd.DataFrame\n",
    "        The DataFrame containing the sequences.\n",
    "    colname: str\n",
    "        The name of the column containing the sequences.\n",
    "    model_name: str, optional (default=\"esm2_t33_650M_UR50D\")\n",
    "        The name of the ESM model to use for the embeddings.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        The DataFrame containing the ESM embeddings.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize distributed world with world_size 1\n",
    "    url = \"tcp://localhost:23456\"\n",
    "    torch.distributed.init_process_group(backend=\"nccl\", init_method=url, world_size=1, rank=0)\n",
    "\n",
    "    # Download model data from the hub\n",
    "    model_data, regression_data = esm.pretrained._download_model_and_regression_data(model_name)\n",
    "\n",
    "    # Initialize the model with FSDP wrapper\n",
    "    fsdp_params = dict(\n",
    "        mixed_precision=True,\n",
    "        flatten_parameters=True,\n",
    "        state_dict_device=torch.device(\"cpu\"),  # reduce GPU mem usage\n",
    "        cpu_offload=True,  # enable cpu offloading\n",
    "    )\n",
    "\n",
    "    with enable_wrap(wrapper_cls=FSDP, **fsdp_params):\n",
    "        model, vocab = esm.pretrained.load_model_and_alphabet_core(\n",
    "            model_name, model_data, regression_data\n",
    "        )\n",
    "        batch_converter = vocab.get_batch_converter()\n",
    "        model.eval()\n",
    "\n",
    "        # Wrap each layer in FSDP separately\n",
    "        for name, child in model.named_children():\n",
    "            if name == \"layers\":\n",
    "                for layer_name, layer in child.named_children():\n",
    "                    wrapped_layer = wrap(layer)\n",
    "                    setattr(child, layer_name, wrapped_layer)\n",
    "        model = wrap(model)\n",
    "\n",
    "        # Define the feature extraction function\n",
    "        def get_feature(r, colname=colname) -> np.ndarray:\n",
    "            data = [('protein', r[colname])]\n",
    "            labels, strs, tokens = batch_converter(data)\n",
    "            with torch.no_grad():\n",
    "                results = model(tokens.cuda(), repr_layers=[33], return_contacts=True)\n",
    "            rpr = results[\"representations\"][33].squeeze()\n",
    "            rpr = rpr[1 : len(r[colname]) + 1].mean(0).detach().cpu().numpy()\n",
    "\n",
    "            del results, labels, strs, tokens, data #especially need to delete those on cuda: tokens, results\n",
    "            gc.collect()\n",
    "\n",
    "            return rpr\n",
    "        \n",
    "        # Apply the feature extraction function to each row in the DataFrame\n",
    "        series = df.apply(get_feature, axis=1)\n",
    "        df_feature = pd.DataFrame(series.tolist())\n",
    "\n",
    "        return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kras_seq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['ID','g12d_seq']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ProcessGroupNCCL is only supported with GPUs, no GPUs found!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m feature \u001b[38;5;241m=\u001b[39m \u001b[43mesm_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mg12d_seq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mesm_embeddings\u001b[0;34m(df, colname, model_name)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Initialize distributed world with world_size 1\u001b[39;00m\n\u001b[1;32m     21\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtcp://localhost:23456\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_process_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnccl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Download model data from the hub\u001b[39;00m\n\u001b[1;32m     25\u001b[0m model_data, regression_data \u001b[38;5;241m=\u001b[39m esm\u001b[38;5;241m.\u001b[39mpretrained\u001b[38;5;241m.\u001b[39m_download_model_and_regression_data(model_name)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/distributed/distributed_c10d.py:602\u001b[0m, in \u001b[0;36minit_process_group\u001b[0;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[38;5;66;03m# Use a PrefixStore to avoid accidental overrides of keys used by\u001b[39;00m\n\u001b[1;32m    599\u001b[0m         \u001b[38;5;66;03m# different systems (e.g. RPC) in case the store is multi-tenant.\u001b[39;00m\n\u001b[1;32m    600\u001b[0m         store \u001b[38;5;241m=\u001b[39m PrefixStore(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_pg\u001b[39m\u001b[38;5;124m\"\u001b[39m, store)\n\u001b[0;32m--> 602\u001b[0m     default_pg \u001b[38;5;241m=\u001b[39m \u001b[43m_new_process_group_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpg_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpg_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m     _update_default_pg(default_pg)\n\u001b[1;32m    614\u001b[0m _pg_group_ranks[GroupMember\u001b[38;5;241m.\u001b[39mWORLD] \u001b[38;5;241m=\u001b[39m {i: i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(GroupMember\u001b[38;5;241m.\u001b[39mWORLD\u001b[38;5;241m.\u001b[39msize())}  \u001b[38;5;66;03m# type: ignore[attr-defined, index]\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/distributed/distributed_c10d.py:738\u001b[0m, in \u001b[0;36m_new_process_group_helper\u001b[0;34m(world_size, rank, group_ranks, backend, store, pg_options, group_name, timeout)\u001b[0m\n\u001b[1;32m    735\u001b[0m     pg_options\u001b[38;5;241m.\u001b[39mis_high_priority_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     pg_options\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m=\u001b[39m timeout\n\u001b[0;32m--> 738\u001b[0m pg \u001b[38;5;241m=\u001b[39m \u001b[43mProcessGroupNCCL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpg_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m# In debug mode and if GLOO is available, wrap in a wrapper PG that\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;66;03m# enables enhanced collective checking for debugability.\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_debug_level() \u001b[38;5;241m==\u001b[39m DebugLevel\u001b[38;5;241m.\u001b[39mDETAIL:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ProcessGroupNCCL is only supported with GPUs, no GPUs found!"
     ]
    }
   ],
   "source": [
    "feature = esm_embeddings(df,'g12d_seq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
